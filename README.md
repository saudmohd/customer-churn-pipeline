# Customer Churn Prediction Pipeline ğŸš€

This project builds a robust and scalable data engineering pipeline to predict customer churn using batch or streaming data sources. It includes ingestion, transformation, feature engineering, model training, prediction, and dashboard visualization.

## ğŸ“Š Overview

The pipeline:
- Ingests customer activity data (batch or streaming)
- Transforms and cleans the data using PySpark
- Engineers churn-relevant features
- Trains an XGBoost model to predict churn
- Outputs predictions to a database or dashboard
- Visualizes results via a Streamlit dashboard

## âš™ï¸ Tech Stack

- **Apache Kafka** / CSV for ingestion
- **Apache Spark / Pandas** for transformation
- **Airflow** for orchestration
- **PostgreSQL / S3** for storage
- **XGBoost / Scikit-learn** for modeling
- **Streamlit** for dashboard
- **Feast** (optional) for feature store

customer-churn-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Original unprocessed data (CSV)
â”‚   â””â”€â”€ processed/                  # Cleaned and transformed data
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ kafka_producer.py          # Streaming data producer
â”‚   â””â”€â”€ batch_ingest.py            # Batch ingestion script
â”‚
â”œâ”€â”€ processing/
â”‚   â””â”€â”€ churn_transform.py         # Data cleaning & transformation logic (Spark/Pandas)
â”‚
â”œâ”€â”€ features/
â”‚   â””â”€â”€ build_features.py          # Feature engineering logic
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ train_model.py             # Model training (XGBoost)
â”‚   â”œâ”€â”€ evaluate_model.py          # Evaluation metrics
â”‚   â””â”€â”€ model.pkl                  # Serialized trained model
â”‚
â”œâ”€â”€ prediction/
â”‚   â””â”€â”€ batch_predict.py           # Make churn predictions on new data
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                     # Streamlit dashboard for results
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ churn_pipeline_dag.py      # Airflow DAG for orchestrating the pipeline
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                # Configuration values for paths, thresholds, etc.
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ helpers.py                 # Common utility functions
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA.ipynb                  # Jupyter Notebook for exploration & insights
â”‚
â”œâ”€â”€ .gitignore                     # Ignore system and virtual files
â”œâ”€â”€ requirements.txt               # Project dependencies
â”œâ”€â”€ README.md                      # Project overview and usage
â””â”€â”€ LICENSE                        # Project license


## ğŸš€ Getting Started

```bash
# Clone the repo
git clone https://github.com/yourusername/customer-churn-pipeline.git
cd customer-churn-pipeline

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

